{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:23:59.575522Z","iopub.execute_input":"2025-05-19T16:23:59.575890Z","iopub.status.idle":"2025-05-19T16:24:01.289419Z","shell.execute_reply.started":"2025-05-19T16:23:59.575837Z","shell.execute_reply":"2025-05-19T16:24:01.288287Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!pip install torch torchvision torchaudio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:24:06.948508Z","iopub.execute_input":"2025-05-19T16:24:06.948796Z","iopub.status.idle":"2025-05-19T16:24:10.802489Z","shell.execute_reply.started":"2025-05-19T16:24:06.948776Z","shell.execute_reply":"2025-05-19T16:24:10.801183Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip install torch-geometric torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cpu.html","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:24:20.092627Z","iopub.execute_input":"2025-05-19T16:24:20.092959Z","iopub.status.idle":"2025-05-19T16:24:23.947047Z","shell.execute_reply.started":"2025-05-19T16:24:20.092929Z","shell.execute_reply":"2025-05-19T16:24:23.945800Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\nRequirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\nRequirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt20cpu)\nRequirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt20cpu)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.18)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import random\nimport networkx as nx\nimport torch\nfrom torch_geometric.data import HeteroData\n\ndef generate_random_workflow(num_tasks=5, num_vms=3):\n    G = nx.gn_graph(num_tasks, seed=random.randint(1, 1000))  # Generates DAG\n\n    task_features = []\n    task_ids = list(G.nodes)\n    for i in task_ids:\n        duration = random.randint(5, 20)\n        data_size = random.randint(1, 10)\n        task_features.append([duration, data_size])\n\n    task_x = torch.tensor(task_features, dtype=torch.float)\n\n    vm_features = []\n    for _ in range(num_vms):\n        cpu = random.randint(1, 4)\n        mem = random.randint(4, 16)\n        vm_features.append([cpu, mem])\n    \n    vm_x = torch.tensor(vm_features, dtype=torch.float)\n\n    # Task dependencies\n    edges = list(G.edges)\n    edge_index_task = torch.tensor(edges, dtype=torch.long).t().contiguous()\n\n    # Task to VM assignability (all-to-all)\n    edge_index_assign = torch.tensor([\n        [i for i in range(num_tasks) for _ in range(num_vms)],\n        [j for _ in range(num_tasks) for j in range(num_vms)]\n    ], dtype=torch.long)\n\n    # Edge attributes (estimated execution time per task-vm pair)\n    edge_attr = []\n    for task in task_x:\n        for vm in vm_x:\n            est_time = task[0] / vm[0]  # naive: duration / CPU\n            edge_attr.append([est_time.item()])\n    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n\n    # Ground truth: assign each task to the VM with min exec time\n    labels = []\n    for i, task in enumerate(task_x):\n        best_vm = min(range(num_vms), key=lambda j: task[0] / vm_x[j][0])\n        labels.append(best_vm)\n    y = torch.tensor(labels, dtype=torch.long)\n\n    # Construct hetero graph\n    data = HeteroData()\n    data['task'].x = task_x\n    data['vm'].x = vm_x\n    data['task', 'to', 'task'].edge_index = edge_index_task\n    data['task', 'assign', 'vm'].edge_index = edge_index_assign\n    data['task', 'assign', 'vm'].edge_attr = edge_attr\n    data['task'].y = y\n\n    return data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:24:33.687947Z","iopub.execute_input":"2025-05-19T16:24:33.688964Z","iopub.status.idle":"2025-05-19T16:24:33.699754Z","shell.execute_reply.started":"2025-05-19T16:24:33.688855Z","shell.execute_reply":"2025-05-19T16:24:33.698910Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"data = generate_random_workflow(num_tasks=6, num_vms=3)\nprint(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:24:46.668527Z","iopub.execute_input":"2025-05-19T16:24:46.668837Z","iopub.status.idle":"2025-05-19T16:24:46.684672Z","shell.execute_reply.started":"2025-05-19T16:24:46.668798Z","shell.execute_reply":"2025-05-19T16:24:46.683802Z"}},"outputs":[{"name":"stdout","text":"HeteroData(\n  task={\n    x=[6, 2],\n    y=[6],\n  },\n  vm={ x=[3, 2] },\n  (task, to, task)={ edge_index=[2, 5] },\n  (task, assign, vm)={\n    edge_index=[2, 18],\n    edge_attr=[18, 1],\n  }\n)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from torch_geometric.nn import SAGEConv\n\nclass SchedulerGNN(nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        self.conv1 = HeteroConv({\n            ('task', 'to', 'task'): GCNConv(-1, hidden_channels),\n            ('task', 'assign', 'vm'): SAGEConv((-1, -1), hidden_channels),\n        }, aggr='sum')\n\n        self.lin_task = nn.Linear(hidden_channels, hidden_channels)\n        self.out = nn.Linear(hidden_channels, 3)  # 3 VMs\n\n    def forward(self, x_dict, edge_index_dict):\n        x_dict = self.conv1(x_dict, edge_index_dict)\n        task_repr = self.lin_task(x_dict['task'])\n        return self.out(task_repr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:26:55.190852Z","iopub.execute_input":"2025-05-19T16:26:55.191226Z","iopub.status.idle":"2025-05-19T16:26:55.198057Z","shell.execute_reply.started":"2025-05-19T16:26:55.191202Z","shell.execute_reply":"2025-05-19T16:26:55.196960Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"data = generate_random_workflow(num_tasks=6, num_vms=3)\nmodel = SchedulerGNN(hidden_channels=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nloss_fn = nn.CrossEntropyLoss()\n\nfor epoch in range(100):\n    model.train()\n    out = model(data.x_dict, data.edge_index_dict)\n    loss = loss_fn(out, data['task'].y)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    if epoch % 10 == 0:\n        acc = (out.argmax(dim=1) == data['task'].y).sum().item() / data['task'].y.size(0)\n        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Acc: {acc:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:54:54.122185Z","iopub.execute_input":"2025-05-19T16:54:54.123061Z","iopub.status.idle":"2025-05-19T16:54:54.365789Z","shell.execute_reply.started":"2025-05-19T16:54:54.123024Z","shell.execute_reply":"2025-05-19T16:54:54.364774Z"}},"outputs":[{"name":"stdout","text":"Epoch 0, Loss: 2.5107, Acc: 0.00\nEpoch 10, Loss: 0.0000, Acc: 1.00\nEpoch 20, Loss: 0.0000, Acc: 1.00\nEpoch 30, Loss: 0.0000, Acc: 1.00\nEpoch 40, Loss: 0.0000, Acc: 1.00\nEpoch 50, Loss: 0.0000, Acc: 1.00\nEpoch 60, Loss: 0.0000, Acc: 1.00\nEpoch 70, Loss: 0.0000, Acc: 1.00\nEpoch 80, Loss: 0.0000, Acc: 1.00\nEpoch 90, Loss: 0.0000, Acc: 1.00\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"def simulate_makespan(assignments, durations, vm_count=10):\n    vm_time = [0] * vm_count\n    for i, vm in enumerate(assignments):\n        vm_time[vm] += durations[i]\n    return max(vm_time)\n\ndurations = [int(t[0].item()) for t in data['task'].x]\npred = model(data.x_dict, data.edge_index_dict).argmax(dim=1).tolist()\ntrue = data['task'].y.tolist()\n\nprint(\"Predicted Makespan:\", simulate_makespan(pred, durations))\nprint(\"Optimal Makespan  :\", simulate_makespan(true, durations))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:54:56.830317Z","iopub.execute_input":"2025-05-19T16:54:56.830623Z","iopub.status.idle":"2025-05-19T16:54:56.841359Z","shell.execute_reply.started":"2025-05-19T16:54:56.830599Z","shell.execute_reply":"2025-05-19T16:54:56.840206Z"}},"outputs":[{"name":"stdout","text":"Predicted Makespan: 65\nOptimal Makespan  : 65\n","output_type":"stream"}],"execution_count":38}]}